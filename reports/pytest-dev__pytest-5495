[{"repo": "pytest-dev/pytest", "instance_id": "pytest-dev__pytest-5495", "base_commit": "1aefb24b37c30fba8fd79a744829ca16e252f340", "patch": "diff --git a/src/_pytest/assertion/util.py b/src/_pytest/assertion/util.py\n--- a/src/_pytest/assertion/util.py\n+++ b/src/_pytest/assertion/util.py\n@@ -254,17 +254,38 @@ def _compare_eq_iterable(left, right, verbose=0):\n \n \n def _compare_eq_sequence(left, right, verbose=0):\n+    comparing_bytes = isinstance(left, bytes) and isinstance(right, bytes)\n     explanation = []\n     len_left = len(left)\n     len_right = len(right)\n     for i in range(min(len_left, len_right)):\n         if left[i] != right[i]:\n+            if comparing_bytes:\n+                # when comparing bytes, we want to see their ascii representation\n+                # instead of their numeric values (#5260)\n+                # using a slice gives us the ascii representation:\n+                # >>> s = b'foo'\n+                # >>> s[0]\n+                # 102\n+                # >>> s[0:1]\n+                # b'f'\n+                left_value = left[i : i + 1]\n+                right_value = right[i : i + 1]\n+            else:\n+                left_value = left[i]\n+                right_value = right[i]\n+\n             explanation += [\n-                \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n+                \"At index {} diff: {!r} != {!r}\".format(i, left_value, right_value)\n             ]\n             break\n-    len_diff = len_left - len_right\n \n+    if comparing_bytes:\n+        # when comparing bytes, it doesn't help to show the \"sides contain one or more items\"\n+        # longer explanation, so skip it\n+        return explanation\n+\n+    len_diff = len_left - len_right\n     if len_diff:\n         if len_diff > 0:\n             dir_with_more = \"Left\"\n", "test_patch": "diff --git a/testing/test_assertion.py b/testing/test_assertion.py\n--- a/testing/test_assertion.py\n+++ b/testing/test_assertion.py\n@@ -331,6 +331,27 @@ def test_multiline_text_diff(self):\n         assert \"- spam\" in diff\n         assert \"+ eggs\" in diff\n \n+    def test_bytes_diff_normal(self):\n+        \"\"\"Check special handling for bytes diff (#5260)\"\"\"\n+        diff = callequal(b\"spam\", b\"eggs\")\n+\n+        assert diff == [\n+            \"b'spam' == b'eggs'\",\n+            \"At index 0 diff: b's' != b'e'\",\n+            \"Use -v to get the full diff\",\n+        ]\n+\n+    def test_bytes_diff_verbose(self):\n+        \"\"\"Check special handling for bytes diff (#5260)\"\"\"\n+        diff = callequal(b\"spam\", b\"eggs\", verbose=True)\n+        assert diff == [\n+            \"b'spam' == b'eggs'\",\n+            \"At index 0 diff: b's' != b'e'\",\n+            \"Full diff:\",\n+            \"- b'spam'\",\n+            \"+ b'eggs'\",\n+        ]\n+\n     def test_list(self):\n         expl = callequal([0, 1], [0, 2])\n         assert len(expl) > 1\n", "problem_statement": "Confusing assertion rewriting message with byte strings\nThe comparison with assertion rewriting for byte strings is confusing: \r\n```\r\n    def test_b():\r\n>       assert b\"\" == b\"42\"\r\nE       AssertionError: assert b'' == b'42'\r\nE         Right contains more items, first extra item: 52\r\nE         Full diff:\r\nE         - b''\r\nE         + b'42'\r\nE         ?   ++\r\n```\r\n\r\n52 is the ASCII ordinal of \"4\" here.\r\n\r\nIt became clear to me when using another example:\r\n\r\n```\r\n    def test_b():\r\n>       assert b\"\" == b\"1\"\r\nE       AssertionError: assert b'' == b'1'\r\nE         Right contains more items, first extra item: 49\r\nE         Full diff:\r\nE         - b''\r\nE         + b'1'\r\nE         ?   +\r\n```\r\n\r\nNot sure what should/could be done here.\n", "hints_text": "hmmm yes, this ~kinda makes sense as `bytes` objects are sequences of integers -- we should maybe just omit the \"contains more items\" messaging for bytes objects?", "created_at": "2019-06-25T23:41:16Z", "version": "4.6", "FAIL_TO_PASS": "[\"testing/test_assertion.py::TestAssert_reprcompare::test_bytes_diff_normal\", \"testing/test_assertion.py::TestAssert_reprcompare::test_bytes_diff_verbose\"]", "PASS_TO_PASS": "[\"testing/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types\", \"testing/test_assertion.py::TestAssert_reprcompare::test_different_types\", \"testing/test_assertion.py::TestAssert_reprcompare::test_summary\", \"testing/test_assertion.py::TestAssert_reprcompare::test_text_diff\", \"testing/test_assertion.py::TestAssert_reprcompare::test_text_skipping\", \"testing/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose\", \"testing/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff\", \"testing/test_assertion.py::TestAssert_reprcompare::test_list\", \"testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\\\n\", \"testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\\\n\", \"testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\\\n\", \"testing/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths\", \"testing/test_assertion.py::TestAssert_reprcompare::test_dict\", \"testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting\", \"testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1\", \"testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2\", \"testing/test_assertion.py::TestAssert_reprcompare::test_dict_different_items\", \"testing/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items\", \"testing/test_assertion.py::TestAssert_reprcompare::test_set\", \"testing/test_assertion.py::TestAssert_reprcompare::test_frozenzet\", \"testing/test_assertion.py::TestAssert_reprcompare::test_Sequence\", \"testing/test_assertion.py::TestAssert_reprcompare::test_list_tuples\", \"testing/test_assertion.py::TestAssert_reprcompare::test_repr_verbose\", \"testing/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr\", \"testing/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty\", \"testing/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc\", \"testing/test_assertion.py::TestAssert_reprcompare::test_unicode\", \"testing/test_assertion.py::TestAssert_reprcompare::test_nonascii_text\", \"testing/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation\", \"testing/test_assertion.py::TestAssert_reprcompare::test_mojibake\", \"testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_simple\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_where\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_and\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_where_nested\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_newline\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where\", \"testing/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where\", \"testing/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list\", \"testing/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars\", \"testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings\", \"testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars\", \"testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_EQ_max_chars\", \"testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_4_lines_when_first_4_lines_are_GT_max_chars\", \"testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_1_line_when_first_line_is_GT_max_chars\", \"testing/test_assertion.py::test_reprcompare_notin\", \"testing/test_assertion.py::test_reprcompare_whitespaces\", \"testing/test_assertion.py::test_exit_from_assertrepr_compare\", \"testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[plain-True]\", \"testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[plain-False]\", \"testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[rewrite-True]\", \"testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[rewrite-False]\", \"testing/test_assertion.py::TestImportHookInstallation::test_rewrite_assertions_pytester_plugin\", \"testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite[plain]\", \"testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite[rewrite]\", \"testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names[str]\", \"testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names[list]\", \"testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names_correctly\", \"testing/test_assertion.py::TestImportHookInstallation::test_rewrite_ast\", \"testing/test_assertion.py::TestBinReprIntegration::test_pytest_assertrepr_compare_called\", \"testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses\", \"testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses_verbose\", \"testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses_with_attribute_comparison_off\", \"testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_comparing_two_different_data_classes\", \"testing/test_assertion.py::TestFormatExplanation::test_special_chars_full\", \"testing/test_assertion.py::TestTruncateExplanation::test_full_output_truncated\", \"testing/test_assertion.py::test_python25_compile_issue257\", \"testing/test_assertion.py::test_rewritten\", \"testing/test_assertion.py::test_pytest_assertrepr_compare_integration\", \"testing/test_assertion.py::test_sequence_comparison_uses_repr\", \"testing/test_assertion.py::test_assertrepr_loaded_per_dir\", \"testing/test_assertion.py::test_assertion_options\", \"testing/test_assertion.py::test_triple_quoted_string_issue113\", \"testing/test_assertion.py::test_traceback_failure\", \"testing/test_assertion.py::test_exception_handling_no_traceback\", \"testing/test_assertion.py::test_warn_missing\", \"testing/test_assertion.py::test_recursion_source_decode\", \"testing/test_assertion.py::test_AssertionError_message\", \"testing/test_assertion.py::test_diff_newline_at_end\", \"testing/test_assertion.py::test_assert_tuple_warning\", \"testing/test_assertion.py::test_assert_indirect_tuple_no_warning\", \"testing/test_assertion.py::test_assert_with_unicode\", \"testing/test_assertion.py::test_raise_unprintable_assertion_error\", \"testing/test_assertion.py::test_raise_assertion_error_raisin_repr\", \"testing/test_assertion.py::test_issue_1944\"]", "environment_setup_commit": "d5843f89d3c008ddcb431adbc335b080a79e617e"}, "On branch main\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   src/_pytest/assertion/util.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\ncommit 1aefb24b37c30fba8fd79a744829ca16e252f340\nMerge: 64a636522 bd647fdd8\nAuthor: Bruno Oliveira <nicoddemus@gmail.com>\nDate:   Tue Jun 25 20:02:02 2019 -0300\n\n    Merge features into master (#5491)\n    \n    Merge features into master\n\ndiff --git a/src/_pytest/assertion/util.py b/src/_pytest/assertion/util.py\nindex 762e5761d..b808cb509 100644\n--- a/src/_pytest/assertion/util.py\n+++ b/src/_pytest/assertion/util.py\n@@ -254,17 +254,38 @@ def _compare_eq_iterable(left, right, verbose=0):\n \n \n def _compare_eq_sequence(left, right, verbose=0):\n+    comparing_bytes = isinstance(left, bytes) and isinstance(right, bytes)\n     explanation = []\n     len_left = len(left)\n     len_right = len(right)\n     for i in range(min(len_left, len_right)):\n         if left[i] != right[i]:\n+            if comparing_bytes:\n+                # when comparing bytes, we want to see their ascii representation\n+                # instead of their numeric values (#5260)\n+                # using a slice gives us the ascii representation:\n+                # >>> s = b'foo'\n+                # >>> s[0]\n+                # 102\n+                # >>> s[0:1]\n+                # b'f'\n+                left_value = left[i : i + 1]\n+                right_value = right[i : i + 1]\n+            else:\n+                left_value = left[i]\n+                right_value = right[i]\n+\n             explanation += [\n-                \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n+                \"At index {} diff: {!r} != {!r}\".format(i, left_value, right_value)\n             ]\n             break\n-    len_diff = len_left - len_right\n \n+    if comparing_bytes:\n+        # when comparing bytes, it doesn't help to show the \"sides contain one or more items\"\n+        # longer explanation, so skip it\n+        return explanation\n+\n+    len_diff = len_left - len_right\n     if len_diff:\n         if len_diff > 0:\n             dir_with_more = \"Left\"\nObtaining file:///testbed\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Checking if build backend supports build_editable: started\n  Checking if build backend supports build_editable: finished with status 'done'\n  Getting requirements to build editable: started\n  Getting requirements to build editable: finished with status 'done'\n  Preparing editable metadata (pyproject.toml): started\n  Preparing editable metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: py>=1.5.0 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (1.11.0)\nRequirement already satisfied: packaging in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (23.1)\nRequirement already satisfied: attrs>=17.4.0 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (23.1.0)\nRequirement already satisfied: more-itertools>=4.0.0 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (10.1.0)\nRequirement already satisfied: atomicwrites>=1.0 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (1.4.1)\nRequirement already satisfied: pluggy<1.0,>=0.12 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (0.13.1)\nRequirement already satisfied: importlib-metadata>=0.12 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (8.5.0)\nRequirement already satisfied: wcwidth in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from pytest==4.6.1.dev144+g1aefb24b3.d20220101) (0.2.6)\nRequirement already satisfied: zipp>=3.20 in /opt/miniconda3/envs/testbed/lib/python3.9/site-packages (from importlib-metadata>=0.12->pytest==4.6.1.dev144+g1aefb24b3.d20220101) (3.20.2)\nBuilding wheels for collected packages: pytest\n  Building editable for pytest (pyproject.toml): started\n  Building editable for pytest (pyproject.toml): finished with status 'done'\n  Created wheel for pytest: filename=pytest-4.6.1.dev144+g1aefb24b3.d20220101-0.editable-py3-none-any.whl size=4920 sha256=da59cc50ab5b93288ebe933e23bb33ca219f6b2333af2ab50f70287498cff0fa\n  Stored in directory: /tmp/pip-ephem-wheel-cache-difyvod3/wheels/7d/66/67/70d1ee2124ccf21d601c352e25cdca10f611f7c8b3f9ffb9e4\nSuccessfully built pytest\nInstalling collected packages: pytest\n  Attempting uninstall: pytest\n    Found existing installation: pytest 4.6.1.dev144+g1aefb24b3\n    Uninstalling pytest-4.6.1.dev144+g1aefb24b3:\n      Successfully uninstalled pytest-4.6.1.dev144+g1aefb24b3\nSuccessfully installed pytest-4.6.1.dev144+g1aefb24b3.d20220101\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /testbed, inifile: tox.ini\ncollected 93 items\n\ntesting/test_assertion.py ................................FFF........... [ 49%]\n..................FF...........................                          [100%]\n\n=================================== FAILURES ===================================\n_________________ TestAssert_reprcompare_attrsclass.test_attrs _________________\n\nself = <test_assertion.TestAssert_reprcompare_attrsclass object at 0x7fd8487722b0>\n\n    def test_attrs(self):\n        @attr.s\n        class SimpleDataObject:\n            field_a = attr.ib()\n            field_b = attr.ib()\n    \n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"c\")\n    \n        lines = callequal(left, right)\n>       assert lines[1].startswith(\"Omitting 1 identical item\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x7fd848f8ec10>('Omitting 1 identical item')\nE        +    where <built-in method startswith of str object at 0x7fd848f8ec10> = '(pytest_assertion plugin: representation of details failed.  Probably an object has a faulty __repr__.)'.startswith\n\ntesting/test_assertion.py:667: AssertionError\n_____________ TestAssert_reprcompare_attrsclass.test_attrs_verbose _____________\n\nself = <test_assertion.TestAssert_reprcompare_attrsclass object at 0x7fd848710880>\n\n    def test_attrs_verbose(self):\n        @attr.s\n        class SimpleDataObject:\n            field_a = attr.ib()\n            field_b = attr.ib()\n    \n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"c\")\n    \n        lines = callequal(left, right, verbose=2)\n>       assert lines[1].startswith(\"Matching attributes:\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x7fd848f8ec10>('Matching attributes:')\nE        +    where <built-in method startswith of str object at 0x7fd848f8ec10> = '(pytest_assertion plugin: representation of details failed.  Probably an object has a faulty __repr__.)'.startswith\n\ntesting/test_assertion.py:682: AssertionError\n__ TestAssert_reprcompare_attrsclass.test_attrs_with_attribute_comparison_off __\n\nself = <test_assertion.TestAssert_reprcompare_attrsclass object at 0x7fd848210a00>\n\n    def test_attrs_with_attribute_comparison_off(self):\n        @attr.s\n        class SimpleDataObject:\n            field_a = attr.ib()\n            field_b = attr.ib(cmp=False)\n    \n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"b\")\n    \n        lines = callequal(left, right, verbose=2)\n>       assert lines[1].startswith(\"Matching attributes:\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x7fd848f8ec10>('Matching attributes:')\nE        +    where <built-in method startswith of str object at 0x7fd848f8ec10> = '(pytest_assertion plugin: representation of details failed.  Probably an object has a faulty __repr__.)'.startswith\n\ntesting/test_assertion.py:696: AssertionError\n_______ TestImportHookInstallation.test_installed_plugin_rewrite[plain] ________\n\nself = <test_assertion.TestImportHookInstallation object at 0x7fd8486b7dc0>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0')>\nmode = 'plain'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fd8486b7940>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: 'E       AssertionError'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x7fd8486b74c0>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7fd84816c220>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n==================================== PASSES ====================================\n____ TestImportHookInstallation.test_conftest_assertion_rewrite[plain-True] ____\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite0/runpytest-0 --assert=plain\n     in: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite0\ncollected 1 item\n\nfoo/tests/test_foo.py F                                                  [100%]\n\n=================================== FAILURES ===================================\n_____________________________________ test _____________________________________\n\ncheck_first = <function check_first.<locals>.check at 0x7fd67df36280>\n\n    def test(check_first):\n>       check_first([10, 30], 30)\n\nfoo/tests/test_foo.py:2: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nvalues = [30], value = 30\n\n    def check(values, value):\n>       assert values.pop(0) == value\nE       AssertionError\n\nconftest.py:5: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n___ TestImportHookInstallation.test_conftest_assertion_rewrite[plain-False] ____\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite1/runpytest-0 --assert=plain\n     in: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite1\ncollected 1 item\n\nfoo/tests/test_foo.py F                                                  [100%]\n\n=================================== FAILURES ===================================\n_____________________________________ test _____________________________________\n\ncheck_first = <function check_first.<locals>.check at 0x7f1bc314d280>\n\n    def test(check_first):\n>       check_first([10, 30], 30)\n\nfoo/tests/test_foo.py:2: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nvalues = [30], value = 30\n\n    def check(values, value):\n>       assert values.pop(0) == value\nE       AssertionError\n\nfoo/conftest.py:5: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n___ TestImportHookInstallation.test_conftest_assertion_rewrite[rewrite-True] ___\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite2/runpytest-0 --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite2\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite2\ncollected 1 item\n\nfoo/tests/test_foo.py F                                                  [100%]\n\n=================================== FAILURES ===================================\n_____________________________________ test _____________________________________\n\ncheck_first = <function check_first.<locals>.check at 0x7f1def6a5280>\n\n    def test(check_first):\n>       check_first([10, 30], 30)\n\nfoo/tests/test_foo.py:2: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nvalues = [30], value = 30\n\n    def check(values, value):\n>       assert values.pop(0) == value\nE       assert 10 == 30\nE        +  where 10 = <built-in method pop of list object at 0x7f1dee806180>(0)\nE        +    where <built-in method pop of list object at 0x7f1dee806180> = [30].pop\n\nconftest.py:5: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n__ TestImportHookInstallation.test_conftest_assertion_rewrite[rewrite-False] ___\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite3/runpytest-0 --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite3\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_conftest_assertion_rewrite3\ncollected 1 item\n\nfoo/tests/test_foo.py F                                                  [100%]\n\n=================================== FAILURES ===================================\n_____________________________________ test _____________________________________\n\ncheck_first = <function check_first.<locals>.check at 0x7f3866dcd280>\n\n    def test(check_first):\n>       check_first([10, 30], 30)\n\nfoo/tests/test_foo.py:2: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nvalues = [30], value = 30\n\n    def check(values, value):\n>       assert values.pop(0) == value\nE       assert 10 == 30\nE        +  where 10 = <built-in method pop of list object at 0x7f386615edc0>(0)\nE        +    where <built-in method pop of list object at 0x7f386615edc0> = [30].pop\n\nfoo/conftest.py:5: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n______ TestImportHookInstallation.test_rewrite_assertions_pytester_plugin ______\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_rewrite_assertions_pytester_plugin0/runpytest-0\n     in: /tmp/pytest-of-root/pytest-0/test_rewrite_assertions_pytester_plugin0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_rewrite_assertions_pytester_plugin0\ncollected 1 item\n\ntest_rewrite_assertions_pytester_plugin.py F                             [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_dummy_failure ______________________________\n\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-0/test_rewrite_assertions_pytester_plugin0/runpytest-0/test_dummy_failure0')>\n\n    def test_dummy_failure(testdir):  # how meta!\n        testdir.makepyfile('def test(): assert 0')\n        r = testdir.inline_run()\n>       r.assertoutcome(passed=1)\n\n../../test_rewrite_assertions_pytester_plugin.py:5: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <_pytest.pytester.HookRecorder object at 0x7f8ebbde0850>, passed = 1\nskipped = 0, failed = 0\n\n    def assertoutcome(self, passed=0, skipped=0, failed=0):\n        realpassed, realskipped, realfailed = self.listoutcomes()\n>       assert passed == len(realpassed)\nE       assert 1 == 0\nE        +  where 0 = len([])\n\n/testbed/src/_pytest/pytester.py:302: AssertionError\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_rewrite_assertions_pytester_plugin0/runpytest-0/test_dummy_failure0\ncollected 1 item\n\ntest_dummy_failure.py F                                                  [100%]\n\n=================================== FAILURES ===================================\n_____________________________________ test _____________________________________\n\n>   def test(): assert 0\nE   assert 0\n\ntest_dummy_failure.py:1: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n=========================== 1 failed in 0.06 seconds ===========================\n________ TestImportHookInstallation.test_pytest_plugins_rewrite[plain] _________\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite0/runpytest-0 --assert=plain\n     in: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite0\ncollected 1 item\n\ntest_foo.py F                                                            [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_foo ___________________________________\n\ncheck_first = <function check_first.<locals>.check at 0x7fee8e2a6280>\n\n    def test_foo(check_first):\n>       check_first([10, 30], 30)\n\ntest_foo.py:2: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nvalues = [30], value = 30\n\n    def check(values, value):\n>       assert values.pop(0) == value\nE       AssertionError\n\nham.py:5: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n_______ TestImportHookInstallation.test_pytest_plugins_rewrite[rewrite] ________\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite1/runpytest-0 --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite1\ncollected 1 item\n\ntest_foo.py F                                                            [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_foo ___________________________________\n\ncheck_first = <function check_first.<locals>.check at 0x7f76fcf36280>\n\n    def test_foo(check_first):\n>       check_first([10, 30], 30)\n\ntest_foo.py:2: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nvalues = [30], value = 30\n\n    def check(values, value):\n>       assert values.pop(0) == value\nE       assert 10 == 30\nE        +  where 10 = <built-in method pop of list object at 0x7f76fc2aca80>(0)\nE        +    where <built-in method pop of list object at 0x7f76fc2aca80> = [30].pop\n\nham.py:5: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n___ TestImportHookInstallation.test_pytest_plugins_rewrite_module_names[str] ___\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names0/runpytest-0 --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names0\ncollected 1 item\n\ntest_foo.py .                                                            [100%]\n\n=========================== 1 passed in 0.01 seconds ===========================\n__ TestImportHookInstallation.test_pytest_plugins_rewrite_module_names[list] ___\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names1/runpytest-0 --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names1\ncollected 1 item\n\ntest_foo.py .                                                            [100%]\n\n=========================== 1 passed in 0.01 seconds ===========================\n_ TestImportHookInstallation.test_pytest_plugins_rewrite_module_names_correctly _\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names_correctly0/runpytest-0 --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names_correctly0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_pytest_plugins_rewrite_module_names_correctly0\ncollected 1 item\n\ntest_foo.py .                                                            [100%]\n\n=========================== 1 passed in 0.01 seconds ===========================\n_________________ TestImportHookInstallation.test_rewrite_ast __________________\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_rewrite_ast0/runpytest-0 --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_rewrite_ast0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_rewrite_ast0\ncollected 2 items\n\ntest_pkg.py FF                                                           [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_tool ___________________________________\n\ntool = <function tool at 0x7f4f9ac7ddc0>\n\n    def test_tool(tool):\n>       tool()\n\ntest_pkg.py:3: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def tool():\n        a, b = 2, 3\n>       assert a == b\nE       assert 2 == 3\n\npkg/helper.py:3: AssertionError\n__________________________________ test_other __________________________________\n\n    def test_other():\n>       pkg.other.tool()\n\ntest_pkg.py:5: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def tool():\n>       assert values.pop() == 3\nE       AssertionError\n\npkg/other.py:3: AssertionError\n=========================== 2 failed in 0.03 seconds ===========================\n_________ TestBinReprIntegration.test_pytest_assertrepr_compare_called _________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /tmp/pytest-of-root/pytest-0/test_pytest_assertrepr_compare_called0\ncollecting ... collected 2 items\n\ntest_pytest_assertrepr_compare_called.py::test_hello FAILED              [ 50%]\ntest_pytest_assertrepr_compare_called.py::test_check PASSED              [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_hello __________________________________\n\n    def test_hello():\n>       assert 0 == 1\nE       assert 0 == 1\nE         -0\nE         +1\n\ntest_pytest_assertrepr_compare_called.py:2: AssertionError\n====================== 1 failed, 1 passed in 0.01 seconds ======================\n______________ TestAssert_reprcompare_dataclass.test_dataclasses _______________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_dataclasses0\ncollected 1 item\n\ntest_compare_dataclasses.py F                                            [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_dataclasses _______________________________\n\n    def test_dataclasses():\n        @dataclass\n        class SimpleDataObject:\n            field_a: int = field()\n            field_b: int = field()\n    \n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"c\")\n    \n>       assert left == right\nE       AssertionError: assert test_dataclas..., field_b='b') == test_dataclass..., field_b='c')\nE         Omitting 1 identical items, use -vv to show\nE         Differing attributes:\nE         field_b: 'b' != 'c'\n\ntest_compare_dataclasses.py:14: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n__________ TestAssert_reprcompare_dataclass.test_dataclasses_verbose ___________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /tmp/pytest-of-root/pytest-0/test_dataclasses_verbose0\ncollecting ... collected 1 item\n\ntest_compare_dataclasses_verbose.py::test_dataclasses_verbose FAILED     [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_dataclasses_verbose ___________________________\n\n    def test_dataclasses_verbose():\n        @dataclass\n        class SimpleDataObject:\n            field_a: int = field()\n            field_b: int = field()\n    \n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"c\")\n    \n>       assert left == right\nE       AssertionError: assert test_dataclas..., field_b='b') == test_dataclass..., field_b='c')\nE         Matching attributes:\nE         ['field_a']\nE         Differing attributes:\nE         field_b: 'b' != 'c'\n\ntest_compare_dataclasses_verbose.py:14: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n_ TestAssert_reprcompare_dataclass.test_dataclasses_with_attribute_comparison_off _\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /tmp/pytest-of-root/pytest-0/test_dataclasses_with_attribute_comparison_off0\ncollecting ... collected 1 item\n\ntest_compare_dataclasses_field_comparison_off.py::test_dataclasses_with_attribute_comparison_off PASSED [100%]\n\n=========================== 1 passed in 0.01 seconds ===========================\n__ TestAssert_reprcompare_dataclass.test_comparing_two_different_data_classes __\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /tmp/pytest-of-root/pytest-0/test_comparing_two_different_data_classes0\ncollecting ... collected 1 item\n\ntest_compare_two_different_dataclasses.py::test_comparing_two_different_data_classes PASSED [100%]\n\n=========================== 1 passed in 0.01 seconds ===========================\n________________ TestFormatExplanation.test_special_chars_full _________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_special_chars_full0\ncollected 1 item\n\ntest_special_chars_full.py F                                             [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_foo ___________________________________\n\n    def test_foo():\n>       assert '\\n}' == ''\nE       AssertionError: assert '\\n}' == ''\nE         - \nE         - }\n\ntest_special_chars_full.py:2: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n______________ TestTruncateExplanation.test_full_output_truncated ______________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_full_output_truncated0\ncollected 1 item\n\ntest_full_output_truncated.py F                                          [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_many_lines ________________________________\n\n    def test_many_lines():\n        a = list([str(i)[0] * 100 for i in range(7)])\n        b = a[::2]\n        a = '\\n'.join(map(str, a))\n        b = '\\n'.join(map(str, b))\n>       assert a == b\nE       AssertionError: assert '000000000000...6666666666666' == '0000000000000...6666666666666'\nE         Skipping 91 identical leading characters in diff, use -v to show\nE           000000000\nE         - 1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\nE           2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\nE         - 3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\nE           4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\nE         - 555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555...\nE         \nE         ...Full output truncated (2 lines hidden), use '-vv' to show\n\ntest_full_output_truncated.py:6: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /tmp/pytest-of-root/pytest-0/test_full_output_truncated0\ncollecting ... collected 1 item\n\ntest_full_output_truncated.py::test_many_lines FAILED                    [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_many_lines ________________________________\n\n    def test_many_lines():\n        a = list([str(i)[0] * 100 for i in range(7)])\n        b = a[::2]\n        a = '\\n'.join(map(str, a))\n        b = '\\n'.join(map(str, b))\n>       assert a == b\nE       AssertionError: assert '000000000000...6666666666666' == '0000000000000...6666666666666'\nE           0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\nE         - 1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\nE           2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\nE         - 3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\nE           4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\nE         - 5555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\nE           6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666\n\ntest_full_output_truncated.py:6: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_full_output_truncated0\ncollected 1 item\n\ntest_full_output_truncated.py F                                          [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_many_lines ________________________________\n\n    def test_many_lines():\n        a = list([str(i)[0] * 100 for i in range(7)])\n        b = a[::2]\n        a = '\\n'.join(map(str, a))\n        b = '\\n'.join(map(str, b))\n>       assert a == b\nE       AssertionError: assert '000000000000...6666666666666' == '0000000000000...6666666666666'\nE         Skipping 91 identical leading characters in diff, use -v to show\nE           000000000\nE         - 1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\nE           2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\nE         - 3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\nE           4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\nE         - 5555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\nE           6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666\n\ntest_full_output_truncated.py:6: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n________________________ test_python25_compile_issue257 ________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_python25_compile_issue2570\ncollected 1 item\n\ntest_python25_compile_issue257.py F                                      [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_rewritten ________________________________\n\n    def test_rewritten():\n>       assert 1 == 2\nE       assert 1 == 2\n\ntest_python25_compile_issue257.py:2: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n________________________________ test_rewritten ________________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_rewritten0\ncollected 1 item\n\ntest_rewritten.py .                                                      [100%]\n\n=========================== 1 passed in 0.00 seconds ===========================\n__________________ test_pytest_assertrepr_compare_integration __________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_pytest_assertrepr_compare_integration0\ncollected 1 item\n\ntest_pytest_assertrepr_compare_integration.py F                          [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_hello __________________________________\n\n    def test_hello():\n        x = set(range(100))\n        y = x.copy()\n        y.remove(50)\n>       assert x == y\nE       assert {0, 1, 2, 3, 4, 5, ...} == {0, 1, 2, 3, 4, 5, ...}\nE         Extra items in the left set:\nE         50\nE         Use -v to get the full diff\n\ntest_pytest_assertrepr_compare_integration.py:5: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n______________________ test_sequence_comparison_uses_repr ______________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_sequence_comparison_uses_repr0\ncollected 1 item\n\ntest_sequence_comparison_uses_repr.py F                                  [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_hello __________________________________\n\n    def test_hello():\n        x = set(\"hello x\")\n        y = set(\"hello y\")\n>       assert x == y\nE       AssertionError: assert {' ', 'e', 'h', 'l', 'o', 'x'} == {' ', 'e', 'h', 'l', 'o', 'y'}\nE         Extra items in the left set:\nE         'x'\nE         Extra items in the right set:\nE         'y'\nE         Use -v to get the full diff\n\ntest_sequence_comparison_uses_repr.py:4: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n________________________ test_assertrepr_loaded_per_dir ________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_assertrepr_loaded_per_dir0\ncollected 3 items\n\ntest_base.py F                                                           [ 33%]\na/test_a.py F                                                            [ 66%]\nb/test_b.py F                                                            [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_base ___________________________________\n\n>   def test_base(): assert 1 == 2\nE   assert 1 == 2\n\ntest_base.py:1: AssertionError\n____________________________________ test_a ____________________________________\n\n>   def test_a(): assert 1 == 2\nE   assert summary a\n\na/test_a.py:1: AssertionError\n____________________________________ test_b ____________________________________\n\n>   def test_b(): assert 1 == 2\nE   assert summary b\n\nb/test_b.py:1: AssertionError\n=========================== 3 failed in 0.02 seconds ===========================\n____________________________ test_assertion_options ____________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_assertion_options0\ncollected 1 item\n\ntest_assertion_options.py F                                              [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_hello __________________________________\n\n    def test_hello():\n        x = 3\n>       assert x == 4\nE       assert 3 == 4\n\ntest_assertion_options.py:3: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\nrunning: /opt/miniconda3/envs/testbed/bin/python -mpytest --basetemp=/tmp/pytest-of-root/pytest-0/test_assertion_options0/runpytest-0 --assert=plain\n     in: /tmp/pytest-of-root/pytest-0/test_assertion_options0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_assertion_options0\ncollected 1 item\n\ntest_assertion_options.py F                                              [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_hello __________________________________\n\n    def test_hello():\n        x = 3\n>       assert x == 4\nE       AssertionError\n\ntest_assertion_options.py:3: AssertionError\n=========================== 1 failed in 0.02 seconds ===========================\n______________________ test_triple_quoted_string_issue113 ______________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_triple_quoted_string_issue1130\ncollected 1 item\n\ntest_triple_quoted_string_issue113.py F                                  [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_hello __________________________________\n\ncls = <class '_pytest.runner.CallInfo'>\nfunc = <function call_runtest_hook.<locals>.<lambda> at 0x7fd84854d700>\nwhen = 'call'\nreraise = (<class '_pytest.outcomes.Exit'>, <class 'KeyboardInterrupt'>)\n\n    @classmethod\n    def from_call(cls, func, when, reraise=None):\n        #: context of invocation: one of \"setup\", \"call\",\n        #: \"teardown\", \"memocollect\"\n        start = time()\n        excinfo = None\n        try:\n>           result = func()\n\n/testbed/src/_pytest/runner.py:220: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n>       lambda: ihook(item=item, **kwds), when=when, reraise=reraise\n    )\n\n/testbed/src/_pytest/runner.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <_HookCaller 'pytest_runtest_call'>, args = ()\nkwargs = {'item': <Function test_hello>}, notincall = set()\n\n    def __call__(self, *args, **kwargs):\n        if args:\n            raise TypeError(\"hook calling supports only keyword arguments\")\n        assert not self.is_historic()\n        if self.spec and self.spec.argnames:\n            notincall = (\n                set(self.spec.argnames) - set([\"__multicall__\"]) - set(kwargs.keys())\n            )\n            if notincall:\n                warnings.warn(\n                    \"Argument(s) {} which are declared in the hookspec \"\n                    \"can not be found in this hook call\".format(tuple(notincall)),\n                    stacklevel=2,\n                )\n>       return self._hookexec(self, self.get_hookimpls(), kwargs)\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/hooks.py:286: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <_pytest.config.PytestPluginManager object at 0x7fd847db0430>\nhook = <_HookCaller 'pytest_runtest_call'>\nmethods = [<HookImpl plugin_name='runner', plugin=<module '_pytest.runner' from '/testbed/src/_pytest/runner.py'>>, <HookImpl pl...est_hello>>>, <HookImpl plugin_name='logging-plugin', plugin=<_pytest.logging.LoggingPlugin object at 0x7fd847e09d30>>]\nkwargs = {'item': <Function test_hello>}\n\n    def _hookexec(self, hook, methods, kwargs):\n        # called from all hookcaller instances.\n        # enable_tracing will set its own wrapping function at self._inner_hookexec\n>       return self._inner_hookexec(hook, methods, kwargs)\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:93: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook = <_HookCaller 'pytest_runtest_call'>\nhook_impls = [<HookImpl plugin_name='runner', plugin=<module '_pytest.runner' from '/testbed/src/_pytest/runner.py'>>, <HookImpl pl...est_hello>>>, <HookImpl plugin_name='logging-plugin', plugin=<_pytest.logging.LoggingPlugin object at 0x7fd847e09d30>>]\nkwargs = {'item': <Function test_hello>}\n\n    def traced_hookexec(hook, hook_impls, kwargs):\n        before(hook.name, hook_impls, kwargs)\n        outcome = _Result.from_call(lambda: oldcall(hook, hook_impls, kwargs))\n        after(outcome, hook.name, hook_impls, kwargs)\n>       return outcome.get_result()\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:337: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n>   outcome = _Result.from_call(lambda: oldcall(hook, hook_impls, kwargs))\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:335: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook = <_HookCaller 'pytest_runtest_call'>\nmethods = [<HookImpl plugin_name='runner', plugin=<module '_pytest.runner' from '/testbed/src/_pytest/runner.py'>>, <HookImpl pl...est_hello>>>, <HookImpl plugin_name='logging-plugin', plugin=<_pytest.logging.LoggingPlugin object at 0x7fd847e09d30>>]\nkwargs = {'item': <Function test_hello>}\n\n>   self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\n        methods,\n        kwargs,\n        firstresult=hook.spec.opts.get(\"firstresult\") if hook.spec else False,\n    )\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:84: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nitem = <Function test_hello>\n\n    def pytest_runtest_call(item):\n        _update_current_test_var(item, \"call\")\n        sys.last_type, sys.last_value, sys.last_traceback = (None, None, None)\n        try:\n>           item.runtest()\n\n/testbed/src/_pytest/runner.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <Function test_hello>\n\n    def runtest(self):\n        \"\"\" execute the underlying test function. \"\"\"\n>       self.ihook.pytest_pyfunc_call(pyfuncitem=self)\n\n/testbed/src/_pytest/python.py:1451: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <_HookCaller 'pytest_pyfunc_call'>, args = ()\nkwargs = {'pyfuncitem': <Function test_hello>}, notincall = set()\n\n    def __call__(self, *args, **kwargs):\n        if args:\n            raise TypeError(\"hook calling supports only keyword arguments\")\n        assert not self.is_historic()\n        if self.spec and self.spec.argnames:\n            notincall = (\n                set(self.spec.argnames) - set([\"__multicall__\"]) - set(kwargs.keys())\n            )\n            if notincall:\n                warnings.warn(\n                    \"Argument(s) {} which are declared in the hookspec \"\n                    \"can not be found in this hook call\".format(tuple(notincall)),\n                    stacklevel=2,\n                )\n>       return self._hookexec(self, self.get_hookimpls(), kwargs)\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/hooks.py:286: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <_pytest.config.PytestPluginManager object at 0x7fd847db0430>\nhook = <_HookCaller 'pytest_pyfunc_call'>\nmethods = [<HookImpl plugin_name='python', plugin=<module '_pytest.python' from '/testbed/src/_pytest/python.py'>>, <HookImpl plugin_name='skipping', plugin=<module '_pytest.skipping' from '/testbed/src/_pytest/skipping.py'>>]\nkwargs = {'pyfuncitem': <Function test_hello>}\n\n    def _hookexec(self, hook, methods, kwargs):\n        # called from all hookcaller instances.\n        # enable_tracing will set its own wrapping function at self._inner_hookexec\n>       return self._inner_hookexec(hook, methods, kwargs)\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:93: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook = <_HookCaller 'pytest_pyfunc_call'>\nhook_impls = [<HookImpl plugin_name='python', plugin=<module '_pytest.python' from '/testbed/src/_pytest/python.py'>>, <HookImpl plugin_name='skipping', plugin=<module '_pytest.skipping' from '/testbed/src/_pytest/skipping.py'>>]\nkwargs = {'pyfuncitem': <Function test_hello>}\n\n    def traced_hookexec(hook, hook_impls, kwargs):\n        before(hook.name, hook_impls, kwargs)\n        outcome = _Result.from_call(lambda: oldcall(hook, hook_impls, kwargs))\n        after(outcome, hook.name, hook_impls, kwargs)\n>       return outcome.get_result()\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:337: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n>   outcome = _Result.from_call(lambda: oldcall(hook, hook_impls, kwargs))\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:335: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nhook = <_HookCaller 'pytest_pyfunc_call'>\nmethods = [<HookImpl plugin_name='python', plugin=<module '_pytest.python' from '/testbed/src/_pytest/python.py'>>, <HookImpl plugin_name='skipping', plugin=<module '_pytest.skipping' from '/testbed/src/_pytest/skipping.py'>>]\nkwargs = {'pyfuncitem': <Function test_hello>}\n\n>   self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\n        methods,\n        kwargs,\n        firstresult=hook.spec.opts.get(\"firstresult\") if hook.spec else False,\n    )\n\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/manager.py:84: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\npyfuncitem = <Function test_hello>\n\n    @hookimpl(trylast=True)\n    def pytest_pyfunc_call(pyfuncitem):\n        testfunction = pyfuncitem.obj\n        iscoroutinefunction = getattr(inspect, \"iscoroutinefunction\", None)\n        if iscoroutinefunction is not None and iscoroutinefunction(testfunction):\n            msg = \"Coroutine functions are not natively supported and have been skipped.\\n\"\n            msg += \"You need to install a suitable plugin for your async framework, for example:\\n\"\n            msg += \"  - pytest-asyncio\\n\"\n            msg += \"  - pytest-trio\\n\"\n            msg += \"  - pytest-tornasync\"\n            warnings.warn(PytestUnhandledCoroutineWarning(msg.format(pyfuncitem.nodeid)))\n            skip(msg=\"coroutine function and no async plugin installed (see warnings)\")\n        funcargs = pyfuncitem.funcargs\n        testargs = {arg: funcargs[arg] for arg in pyfuncitem._fixtureinfo.argnames}\n>       testfunction(**testargs)\n\n/testbed/src/_pytest/python.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def test_hello():\n>           assert \"\" == '''\n    '''\nE           AssertionError: assert '' == '\\n'\nE             Strings contain only whitespace, escaping them using repr()\nE             - ''\nE             + '\\n'\n\ntest_triple_quoted_string_issue113.py:2: AssertionError\n=========================== 1 failed in 0.06 seconds ===========================\n____________________________ test_traceback_failure ____________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_traceback_failure0\ncollected 1 item\n\ntest_traceback_failure.py F                                              [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_onefails _________________________________\n\n    def test_onefails():\n>       f(3)\n\ntest_traceback_failure.py:6: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nx = 3\n\n    def f(x):\n>       assert x == g()\nE       assert 3 == 2\nE        +  where 2 = g()\n\ntest_traceback_failure.py:4: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_traceback_failure0\ncollected 1 item\n\ntest_traceback_failure.py F                                              [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_onefails _________________________________\n\n    def test_onefails():\n>       f(3)\n\ntest_traceback_failure.py:6: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nx = 3\n\n    def f(x):\n>       assert x == g()\nE       assert 3 == 2\nE        +  where 2 = g()\n\ntest_traceback_failure.py:4: AssertionError\n=========================== 1 failed in 0.00 seconds ===========================\n_____________________ test_exception_handling_no_traceback _____________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_exception_handling_no_traceback0\ncollected 1 item\n\ntest_exception_handling_no_traceback.py F                                [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_multitask_job ______________________________\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/pytest-of-root/pytest-0/test_exception_handling_no_traceback0/test_exception_handling_no_traceback.py\", line 4, in process_task\n    assert n == 10\nAssertionError: assert 1 == 10\n\"\"\"\n\nThe above exception was the direct cause of the following exception:\n\n    def test_multitask_job():\n>       multitask_job()\n\ntest_exception_handling_no_traceback.py:12: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    def multitask_job():\n        tasks = [1]\n        with Pool(processes=1) as pool:\n>           pool.map(process_task, tasks)\n\ntest_exception_handling_no_traceback.py:9: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <multiprocessing.pool.Pool state=TERMINATE pool_size=1>\nfunc = <function process_task at 0x7fd847d731f0>, iterable = [1]\nchunksize = None\n\n    def map(self, func, iterable, chunksize=None):\n        '''\n        Apply `func` to each element in `iterable`, collecting the results\n        in a list that is returned.\n        '''\n>       return self._map_async(func, iterable, mapstar, chunksize).get()\n\n/opt/miniconda3/envs/testbed/lib/python3.9/multiprocessing/pool.py:364: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <multiprocessing.pool.MapResult object at 0x7fd847be2550>, timeout = None\n\n    def get(self, timeout=None):\n        self.wait(timeout)\n        if not self.ready():\n            raise TimeoutError\n        if self._success:\n            return self._value\n        else:\n>           raise self._value\nE           assert 1 == 10\n\n/opt/miniconda3/envs/testbed/lib/python3.9/multiprocessing/pool.py:771: AssertionError\n=========================== 1 failed in 0.05 seconds ===========================\n______________________________ test_warn_missing _______________________________\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python -OO -m pytest -h\n     in: /tmp/pytest-of-root/pytest-0/test_warn_missing0\nusage: pytest.py [options] [file_or_dir] [file_or_dir] [...]\n\npositional arguments:\n  file_or_dir\n\ngeneral:\n  -k EXPRESSION         only run tests which match the given substring\n                        expression. An expression is a python evaluatable\n                        expression where all names are substring-matched\n                        against test names and their parent classes. Example:\n                        -k 'test_method or test_other' matches all test\n                        functions and classes whose name contains\n                        'test_method' or 'test_other', while -k 'not\n                        test_method' matches those that don't contain\n                        'test_method' in their names. -k 'not test_method and\n                        not test_other' will eliminate the matches.\n                        Additionally keywords are matched to classes and\n                        functions containing extra names in their\n                        'extra_keyword_matches' set, as well as functions\n                        which have names assigned directly to them.\n  -m MARKEXPR           only run tests matching given mark expression.\n                        example: -m 'mark1 and not mark2'.\n  --markers             show markers (builtin, plugin and per-project ones).\n  -x, --exitfirst       exit instantly on first error or failed test.\n  --maxfail=num         exit after first num failures or errors.\n  --strict-markers, --strict\n                        markers not registered in the `markers` section of the\n                        configuration file raise errors.\n  -c file               load configuration from `file` instead of trying to\n                        locate one of the implicit configuration files.\n  --continue-on-collection-errors\n                        Force test execution even if collection errors occur.\n  --rootdir=ROOTDIR     Define root directory for tests. Can be relative path:\n                        'root_dir', './root_dir', 'root_dir/another_dir/';\n                        absolute path: '/home/user/root_dir'; path with\n                        variables: '$HOME/root_dir'.\n  --fixtures, --funcargs\n                        show available fixtures, sorted by plugin appearance\n                        (fixtures with leading '_' are only shown with '-v')\n  --fixtures-per-test   show fixtures per test\n  --import-mode={prepend,append}\n                        prepend/append to sys.path when importing test\n                        modules, default is to prepend.\n  --pdb                 start the interactive Python debugger on errors or\n                        KeyboardInterrupt.\n  --pdbcls=modulename:classname\n                        start a custom interactive Python debugger on errors.\n                        For example:\n                        --pdbcls=IPython.terminal.debugger:TerminalPdb\n  --trace               Immediately break when running each test.\n  --capture=method      per-test capturing method: one of fd|sys|no.\n  -s                    shortcut for --capture=no.\n  --runxfail            report the results of xfail tests as if they were not\n                        marked\n  --lf, --last-failed   rerun only the tests that failed at the last run (or\n                        all if none failed)\n  --ff, --failed-first  run all tests but run the last failures first. This\n                        may re-order tests and thus lead to repeated fixture\n                        setup/teardown\n  --nf, --new-first     run tests from new files first, then the rest of the\n                        tests sorted by file mtime\n  --cache-show=[CACHESHOW]\n                        show cache contents, don't perform collection or\n                        tests. Optional argument: glob (default: '*').\n  --cache-clear         remove all cache contents at start of test run.\n  --lfnf={all,none}, --last-failed-no-failures={all,none}\n                        which tests to run with no previously (known)\n                        failures.\n  --sw, --stepwise      exit on test failure and continue from last failing\n                        test next time\n  --stepwise-skip       ignore the first failing test but stop on the next\n                        failing test\n\nreporting:\n  --durations=N         show N slowest setup/test durations (N=0 for all).\n  -v, --verbose         increase verbosity.\n  -q, --quiet           decrease verbosity.\n  --verbosity=VERBOSE   set verbosity\n  -r chars              show extra test summary info as specified by chars:\n                        (f)ailed, (E)rror, (s)kipped, (x)failed, (X)passed,\n                        (p)assed, (P)assed with output, (a)ll except passed\n                        (p/P), or (A)ll. (w)arnings are enabled by default\n                        (see --disable-warnings).\n  --disable-warnings, --disable-pytest-warnings\n                        disable warnings summary\n  -l, --showlocals      show locals in tracebacks (disabled by default).\n  --tb=style            traceback print mode (auto/long/short/line/native/no).\n  --show-capture={no,stdout,stderr,log,all}\n                        Controls how captured stdout/stderr/log is shown on\n                        failed tests. Default is 'all'.\n  --full-trace          don't cut any tracebacks (default is to cut).\n  --color=color         color terminal output (yes/no/auto).\n  --pastebin=mode       send failed|all info to bpaste.net pastebin service.\n  --junit-xml=path      create junit-xml style report file at given path.\n  --junit-prefix=str    prepend prefix to classnames in junit-xml output\n  --result-log=path     DEPRECATED path for machine-readable result log.\n\ncollection:\n  --collect-only        only collect tests, don't execute them.\n  --pyargs              try to interpret all arguments as python packages.\n  --ignore=path         ignore path during collection (multi-allowed).\n  --ignore-glob=path    ignore path pattern during collection (multi-allowed).\n  --deselect=nodeid_prefix\n                        deselect item during collection (multi-allowed).\n  --confcutdir=dir      only load conftest.py's relative to specified dir.\n  --noconftest          Don't load any conftest.py files.\n  --keep-duplicates     Keep duplicate tests.\n  --collect-in-virtualenv\n                        Don't ignore tests in a local virtualenv directory\n  --doctest-modules     run doctests in all .py modules\n  --doctest-report={none,cdiff,ndiff,udiff,only_first_failure}\n                        choose another output format for diffs on doctest\n                        failure\n  --doctest-glob=pat    doctests file matching pattern, default: test*.txt\n  --doctest-ignore-import-errors\n                        ignore doctest ImportErrors\n  --doctest-continue-on-failure\n                        for a given doctest, continue to run after the first\n                        failure\n\ntest session debugging and configuration:\n  --basetemp=dir        base temporary directory for this test run.(warning:\n                        this directory is removed if it exists)\n  --version             display pytest lib version and import information.\n  -h, --help            show help message and configuration info\n  -p name               early-load given plugin module name or entry point\n                        (multi-allowed). To avoid loading of plugins, use the\n                        `no:` prefix, e.g. `no:doctest`.\n  --trace-config        trace considerations of conftest.py files.\n  --debug               store internal tracing debug information in\n                        'pytestdebug.log'.\n  -o OVERRIDE_INI, --override-ini=OVERRIDE_INI\n                        override ini option with \"option=value\" style, e.g.\n                        `-o xfail_strict=True -o cache_dir=cache`.\n  --assert=MODE         Control assertion debugging tools. 'plain' performs no\n                        assertion debugging. 'rewrite' (the default) rewrites\n                        assert statements in test modules on import to provide\n                        assert expression information.\n  --setup-only          only setup fixtures, do not execute tests.\n  --setup-show          show setup of fixtures while executing tests.\n  --setup-plan          show what fixtures and tests would be executed but\n                        don't execute anything.\n\npytest-warnings:\n  -W PYTHONWARNINGS, --pythonwarnings=PYTHONWARNINGS\n                        set which warnings to report, see -W option of python\n                        itself.\n\nlogging:\n  --no-print-logs       disable printing caught logs on failed tests.\n  --log-level=LOG_LEVEL\n                        logging level used by the logging module\n  --log-format=LOG_FORMAT\n                        log format as used by the logging module.\n  --log-date-format=LOG_DATE_FORMAT\n                        log date format as used by the logging module.\n  --log-cli-level=LOG_CLI_LEVEL\n                        cli logging level.\n  --log-cli-format=LOG_CLI_FORMAT\n                        log format as used by the logging module.\n  --log-cli-date-format=LOG_CLI_DATE_FORMAT\n                        log date format as used by the logging module.\n  --log-file=LOG_FILE   path to a file when logging will be written to.\n  --log-file-level=LOG_FILE_LEVEL\n                        log file logging level.\n  --log-file-format=LOG_FILE_FORMAT\n                        log format as used by the logging module.\n  --log-file-date-format=LOG_FILE_DATE_FORMAT\n                        log date format as used by the logging module.\n\n[pytest] ini-options in the first pytest.ini|tox.ini|setup.cfg file found:\n\n  markers (linelist):   markers for test functions\n  empty_parameter_set_mark (string):\n                        default marker for empty parametersets\n  norecursedirs (args): directory patterns to avoid for recursion\n  testpaths (args):     directories to search for tests when no files or\n                        directories are given in the command line.\n  usefixtures (args):   list of default fixtures to be used with this project\n  python_files (args):  glob-style file patterns for Python test module\n                        discovery\n  python_classes (args):\n                        prefixes or glob names for Python test class discovery\n  python_functions (args):\n                        prefixes or glob names for Python test function and\n                        method discovery\n  disable_test_id_escaping_and_forfeit_all_rights_to_community_support (bool):\n                        disable string escape non-ascii characters, might cause\n                        unwanted side effects(use at your own risk)\n  console_output_style (string):\n                        console output: \"classic\", or with additional progress\n                        information (\"progress\" (percentage) | \"count\").\n  xfail_strict (bool):  default for the strict parameter of xfail markers when\n                        not given explicitly (default: False)\n  junit_suite_name (string):\n                        Test suite name for JUnit report\n  junit_logging (string):\n                        Write captured log messages to JUnit report: one of\n                        no|system-out|system-err\n  junit_log_passing_tests (bool):\n                        Capture log information for passing tests to JUnit\n                        report:\n  junit_duration_report (string):\n                        Duration time to report: one of total|call\n  junit_family (string):\n                        Emit XML for schema: one of legacy|xunit1|xunit2\n  doctest_optionflags (args):\n                        option flags for doctests\n  doctest_encoding (string):\n                        encoding used for doctest files\n  cache_dir (string):   cache directory path.\n  filterwarnings (linelist):\n                        Each line specifies a pattern for\n                        warnings.filterwarnings. Processed after -W and\n                        --pythonwarnings.\n  log_print (bool):     default value for --no-print-logs\n  log_level (string):   default value for --log-level\n  log_format (string):  default value for --log-format\n  log_date_format (string):\n                        default value for --log-date-format\n  log_cli (bool):       enable log display during test run (also known as \"live\n                        logging\").\n  log_cli_level (string):\n                        default value for --log-cli-level\n  log_cli_format (string):\n                        default value for --log-cli-format\n  log_cli_date_format (string):\n                        default value for --log-cli-date-format\n  log_file (string):    default value for --log-file\n  log_file_level (string):\n                        default value for --log-file-level\n  log_file_format (string):\n                        default value for --log-file-format\n  log_file_date_format (string):\n                        default value for --log-file-date-format\n  faulthandler_timeout (string):\n                        Dump the traceback of all threads if a test takes more\n                        than TIMEOUT seconds to finish. Not available on\n                        Windows.\n  addopts (args):       extra command line options\n  minversion (string):  minimally required pytest version\n\nenvironment variables:\n  PYTEST_ADDOPTS           extra command line options\n  PYTEST_PLUGINS           comma-separated plugins to load during startup\n  PYTEST_DISABLE_PLUGIN_AUTOLOAD set to disable plugin auto-loading\n  PYTEST_DEBUG             set to enable debug tracing of pytest's internals\n\n\nto see available markers type: pytest --markers\nto see available fixtures type: pytest --fixtures\n(shown according to specified file_or_dir or current dir if not specified; fixtures with leading '_' are only shown with the '-v' option\nrunning: /opt/miniconda3/envs/testbed/bin/python -OO -m pytest\n     in: /tmp/pytest-of-root/pytest-0/test_warn_missing0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_warn_missing0\ncollected 0 items\n\n========================= no tests ran in 0.01 seconds =========================\n----------------------------- Captured stderr call -----------------------------\nWARNING: assertions not in test modules or plugins will be ignored because assert statements are not executed by the underlying Python interpreter (are you using python -O?)\nWARNING: assertions not in test modules or plugins will be ignored because assert statements are not executed by the underlying Python interpreter (are you using python -O?)\n_________________________ test_recursion_source_decode _________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_recursion_source_decode0, inifile: tox.ini\ncollected 1 item\n<Module test_recursion_source_decode.py>\n  <Function test_something>\n\n========================= no tests ran in 0.00 seconds =========================\n_________________________ test_AssertionError_message __________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_AssertionError_message0\ncollected 1 item\n\ntest_AssertionError_message.py F                                         [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_hello __________________________________\n\n    def test_hello():\n        x,y = 1,2\n>       assert 0, (x,y)\nE       AssertionError: (1, 2)\nE       assert 0\n\ntest_AssertionError_message.py:3: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n___________________________ test_diff_newline_at_end ___________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_diff_newline_at_end0\ncollected 1 item\n\ntest_diff_newline_at_end.py F                                            [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_diff ___________________________________\n\n    def test_diff():\n>       assert 'asdf' == 'asdf\\n'\nE       AssertionError: assert 'asdf' == 'asdf\\n'\nE         - asdf\nE         + asdf\nE         ?     +\n\ntest_diff_newline_at_end.py:2: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n__________________________ test_assert_tuple_warning ___________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_assert_tuple_warning0\ncollected 1 item\n\ntest_assert_tuple_warning.py .                                           [100%]\n\n=============================== warnings summary ===============================\ntest_assert_tuple_warning.py:2\n  /tmp/pytest-of-root/pytest-0/test_assert_tuple_warning0/test_assert_tuple_warning.py:2: PytestAssertRewriteWarning: assertion is always true, perhaps remove parentheses?\n    assert(False, 'you shall not pass')\n\n-- Docs: https://docs.pytest.org/en/latest/warnings.html\n===================== 1 passed, 1 warnings in 0.00 seconds =====================\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_assert_tuple_warning0\ncollected 1 item\n\ntest_assert_tuple_warning.py F                                           [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_tuple __________________________________\n\n    def test_tuple():\n>       assert ()\nE       assert ()\n\ntest_assert_tuple_warning.py:2: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n____________________ test_assert_indirect_tuple_no_warning _____________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_assert_indirect_tuple_no_warning0\ncollected 1 item\n\ntest_assert_indirect_tuple_no_warning.py .                               [100%]\n\n=========================== 1 passed in 0.00 seconds ===========================\n___________________________ test_assert_with_unicode ___________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_assert_with_unicode0\ncollected 1 item\n\ntest_assert_with_unicode.py F                                            [100%]\n\n=================================== FAILURES ===================================\n_________________________________ test_unicode _________________________________\n\n    def test_unicode():\n>       assert '\uc720\ub2c8\ucf54\ub4dc' == 'Unicode'\nE       AssertionError: assert '\uc720\ub2c8\ucf54\ub4dc' == 'Unicode'\nE         - \uc720\ub2c8\ucf54\ub4dc\nE         + Unicode\n\ntest_assert_with_unicode.py:2: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n____________________ test_raise_unprintable_assertion_error ____________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_raise_unprintable_assertion_error0\ncollected 1 item\n\ntest_raise_unprintable_assertion_error.py F                              [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_raise_assertion_error __________________________\n\n    def test_raise_assertion_error():\n>       raise AssertionError('\\xff')\nE       AssertionError: \u00ff\n\ntest_raise_unprintable_assertion_error.py:2: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n____________________ test_raise_assertion_error_raisin_repr ____________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_raise_assertion_error_raisin_repr0\ncollected 1 item\n\ntest_raise_assertion_error_raisin_repr.py F                              [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_raising_repr _______________________________\n\n    def test_raising_repr():\n>       raise AssertionError(RaisingRepr())\nE       AssertionError: <unprintable AssertionError object>\n\ntest_raise_assertion_error_raisin_repr.py:5: AssertionError\n=========================== 1 failed in 0.01 seconds ===========================\n_______________________________ test_issue_1944 ________________________________\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-4.6.1.dev144+g1aefb24b3.d20220101, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_issue_19440\ncollected 0 items / 1 errors\n\n==================================== ERRORS ====================================\n_____________________ ERROR collecting test_issue_1944.py ______________________\ntest_issue_1944.py:4: in <module>\n    assert f() == 10\nE   assert None == 10\nE    +  where None = <function f at 0x7fd847bb7c10>()\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 errors during collection !!!!!!!!!!!!!!!!!!!!\n=========================== 1 error in 0.05 seconds ============================\n=========================== short test summary info ============================\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_different_types\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_summary\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_text_diff\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_text_skipping\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_bytes_diff_normal\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_bytes_diff_verbose\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_list\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ]\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ]\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ]\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_dict\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_dict_different_items\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_set\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_frozenzet\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_Sequence\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_list_tuples\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_repr_verbose\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_unicode\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_nonascii_text\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation\nPASSED testing/test_assertion.py::TestAssert_reprcompare::test_mojibake\nPASSED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_simple\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_where\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_and\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_where_nested\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_newline\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where\nPASSED testing/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_EQ_max_chars\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_4_lines_when_first_4_lines_are_GT_max_chars\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_1_line_when_first_line_is_GT_max_chars\nPASSED testing/test_assertion.py::test_reprcompare_notin\nPASSED testing/test_assertion.py::test_reprcompare_whitespaces\nPASSED testing/test_assertion.py::test_exit_from_assertrepr_compare\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[plain-True]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[plain-False]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[rewrite-True]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[rewrite-False]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_rewrite_assertions_pytester_plugin\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite[plain]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite[rewrite]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names[str]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names[list]\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names_correctly\nPASSED testing/test_assertion.py::TestImportHookInstallation::test_rewrite_ast\nPASSED testing/test_assertion.py::TestBinReprIntegration::test_pytest_assertrepr_compare_called\nPASSED testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses\nPASSED testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses_verbose\nPASSED testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses_with_attribute_comparison_off\nPASSED testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_comparing_two_different_data_classes\nPASSED testing/test_assertion.py::TestFormatExplanation::test_special_chars_full\nPASSED testing/test_assertion.py::TestTruncateExplanation::test_full_output_truncated\nPASSED testing/test_assertion.py::test_python25_compile_issue257\nPASSED testing/test_assertion.py::test_rewritten\nPASSED testing/test_assertion.py::test_pytest_assertrepr_compare_integration\nPASSED testing/test_assertion.py::test_sequence_comparison_uses_repr\nPASSED testing/test_assertion.py::test_assertrepr_loaded_per_dir\nPASSED testing/test_assertion.py::test_assertion_options\nPASSED testing/test_assertion.py::test_triple_quoted_string_issue113\nPASSED testing/test_assertion.py::test_traceback_failure\nPASSED testing/test_assertion.py::test_exception_handling_no_traceback\nPASSED testing/test_assertion.py::test_warn_missing\nPASSED testing/test_assertion.py::test_recursion_source_decode\nPASSED testing/test_assertion.py::test_AssertionError_message\nPASSED testing/test_assertion.py::test_diff_newline_at_end\nPASSED testing/test_assertion.py::test_assert_tuple_warning\nPASSED testing/test_assertion.py::test_assert_indirect_tuple_no_warning\nPASSED testing/test_assertion.py::test_assert_with_unicode\nPASSED testing/test_assertion.py::test_raise_unprintable_assertion_error\nPASSED testing/test_assertion.py::test_raise_assertion_error_raisin_repr\nPASSED testing/test_assertion.py::test_issue_1944\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 88 passed in 4.42 seconds ======================\n", {"testing/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_different_types": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_summary": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_text_diff": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_text_skipping": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_bytes_diff_normal": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_bytes_diff_verbose": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_list": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_dict": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_dict_different_items": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_set": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_frozenzet": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_Sequence": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_list_tuples": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_repr_verbose": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_unicode": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_nonascii_text": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare::test_mojibake": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_simple": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_where": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_and": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_where_nested": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_newline": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_EQ_max_chars": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_4_lines_when_first_4_lines_are_GT_max_chars": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_truncates_at_1_line_when_first_line_is_GT_max_chars": "PASSED", "testing/test_assertion.py::test_reprcompare_notin": "PASSED", "testing/test_assertion.py::test_reprcompare_whitespaces": "PASSED", "testing/test_assertion.py::test_exit_from_assertrepr_compare": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[plain-True]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[plain-False]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[rewrite-True]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_conftest_assertion_rewrite[rewrite-False]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_rewrite_assertions_pytester_plugin": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite[plain]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite[rewrite]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names[str]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names[list]": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_pytest_plugins_rewrite_module_names_correctly": "PASSED", "testing/test_assertion.py::TestImportHookInstallation::test_rewrite_ast": "PASSED", "testing/test_assertion.py::TestBinReprIntegration::test_pytest_assertrepr_compare_called": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses_verbose": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_dataclasses_with_attribute_comparison_off": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare_dataclass::test_comparing_two_different_data_classes": "PASSED", "testing/test_assertion.py::TestFormatExplanation::test_special_chars_full": "PASSED", "testing/test_assertion.py::TestTruncateExplanation::test_full_output_truncated": "PASSED", "testing/test_assertion.py::test_python25_compile_issue257": "PASSED", "testing/test_assertion.py::test_rewritten": "PASSED", "testing/test_assertion.py::test_pytest_assertrepr_compare_integration": "PASSED", "testing/test_assertion.py::test_sequence_comparison_uses_repr": "PASSED", "testing/test_assertion.py::test_assertrepr_loaded_per_dir": "PASSED", "testing/test_assertion.py::test_assertion_options": "PASSED", "testing/test_assertion.py::test_triple_quoted_string_issue113": "PASSED", "testing/test_assertion.py::test_traceback_failure": "PASSED", "testing/test_assertion.py::test_exception_handling_no_traceback": "PASSED", "testing/test_assertion.py::test_warn_missing": "PASSED", "testing/test_assertion.py::test_recursion_source_decode": "PASSED", "testing/test_assertion.py::test_AssertionError_message": "PASSED", "testing/test_assertion.py::test_diff_newline_at_end": "PASSED", "testing/test_assertion.py::test_assert_tuple_warning": "PASSED", "testing/test_assertion.py::test_assert_indirect_tuple_no_warning": "PASSED", "testing/test_assertion.py::test_assert_with_unicode": "PASSED", "testing/test_assertion.py::test_raise_unprintable_assertion_error": "PASSED", "testing/test_assertion.py::test_raise_assertion_error_raisin_repr": "PASSED", "testing/test_assertion.py::test_issue_1944": "PASSED", "testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs": "FAILED", "testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose": "FAILED", "testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off": "FAILED", "testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]": "FAILED", "testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]": "FAILED"}]